# 2024-09-16

## 想到了些啥

数一资料到了，尝试刷了一小点，发现考研资料会更倾向于教如何速算、巧算，以及直接记各种性质。

想了想也是，作为考生的话，首要目标是尽可能地考高分。为此，把东西背下来，对着考纲快速学习一些速算巧算法可能是最快的路径。

以此代入我现在的学习目标，我想我可能需要对此做出适配，包括：

- 放宽对时限的要求，对于题目来说【做出来了】就可以，【做得快】并不是我需要掌握的
- 对于各种数学性质，需要理解它。我的目标是将数学内化为自己的工具，借此工具来对未来的机器学习的原理推导能更得心应手
  - 其实就是为了不至于让自己在面对各种公式推导的时候一脸懵逼

## 今天做了啥

- 线性代数视频课：学了
  - 第十二章：学习克莱默法则
  - 第十三章：学习基变换
  - 第十四章：学了特征值、特征向量、特征基，开始听不懂了

## 需要记点啥

### 线性方程组求解

考虑如下方程组：
$$
\begin{matrix}-4x+2y+3z=7\\-x+2z=-8\\-4x+6y-9z=3\end{matrix}
$$
转换为线性代数的表示就是：
$$
\begin{bmatrix}-4&2&3\\-1&0&2\\-4&6&-9\end{bmatrix}\begin{bmatrix}x\\y\\z\end{bmatrix}=\begin{bmatrix}7\\-8\\3\end{bmatrix}
$$
克莱默法则给了一种易于理解但难于计算的方法：依靠行列式。
$$
\begin{matrix}
x=\frac{\det(\begin{bmatrix}\color{Red}{7}&2&3\\\color{Red}{-8}&0&2\\\color{Red}{3}&6&-9\end{bmatrix})}{\det(\begin{bmatrix}-4&2&3\\-1&0&2\\-4&6&-9\end{bmatrix})} \\
y=\frac{\det(\begin{bmatrix}-4&\color{Red}{7}&3\\-1&\color{Red}{-8}&2\\-4&\color{Red}{3}&-9\end{bmatrix})}{\det(\begin{bmatrix}-4&2&3\\-1&0&2\\-4&6&-9\end{bmatrix})} \\
z=\frac{\det(\begin{bmatrix}-4&2&\color{Red}{7}\\-1&0&\color{Red}{-8}\\-4&6&\color{Red}{3}\end{bmatrix})}{\det(\begin{bmatrix}-4&2&3\\-1&0&2\\-4&6&-9\end{bmatrix})}
\end{matrix}
$$
我们可以从几何的角度来理解。

以二维的情况为例：
$$
\begin{bmatrix}2&-1\\0&1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}4\\2\end{bmatrix}
$$
这个方程的几何意义是，已知某个向量在线性变换$\begin{bmatrix}2&-1\\0&1\end{bmatrix}$后成为向量$(4, 2)$，求这个向量的原始向量。

#### 一个错误的思路

我们可以将每个维度分解来考虑。以$y$维为例，向量$(0, y)$在经过线性变换后本质上是经过了类似缩放的操作，最终**可能**会成为$(0, 2)$。

为什么说是可能呢？因为上面的假设考虑的是，缩放前向量$(x, 0)$和$(0, y)$是正交的，缩放后它俩也是正交的。

很可惜，这是错的。

#### 以此为启发的正确思路

虽说上述思路是错的，但其核心思想【缩放】或许是可以用上的，毕竟线性变换的本质就是旋转缩放扭曲。

我们可以考虑换一种思路，不用$(0, y)$来表示$y$的值，而是考虑向量$(x, y)$与$\hat{i}=(1, 0)$围成的面积。显然该面积的值为$y$（先不考虑符号）。

那么经过线性变换$A$后，这个面积显然也会被缩放$\det(A)$倍，即为$y\det(A)$

同时，这个面积在经过线性变换后，即为向量$(4, 2)$与变换后的基向量$\hat{i}=(2, 0)$围成的面积，即为$\det(\begin{bmatrix}2&4\\0&2\end{bmatrix})$

于是可以推导出：$y=\frac{\det(\begin{bmatrix}2&4\\0&2\end{bmatrix})}{\det(\begin{bmatrix}2&-1\\0&1\end{bmatrix})}$

看下面这个图会清晰一些：

![](\img\screenshot-20240916-155941.png)

#### 话又说回来

克莱默法则也只是给出了几何层面上对线性方程组的解的推导，但本质上其方法是$O(n!)$的，真要算还是得用高斯消元法。

但为什么要记这个呢？

可以发现一件事情，这个行列式除法是可以化简的。其存在相当多的冗余步骤。

或许把这个冗余拆完之后就可以看到高斯消元的样子，进而得到高斯消元的几何解释。

> 不过还懒得去证明，哈哈哈

#### 另一种线性方程组的求解方法

还是以这个为例：
$$
\begin{bmatrix}2&-1\\0&1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}4\\2\end{bmatrix}
$$
它表示向量$(x, y)$在线性变换$A$之后，成为了$(4, 2)$。

那么反过来地，向量$(4, 2)$在线性变换$A^{-1}$后，成为了$(x, y)$。（假设$A$可逆）

于是就可以得到一种更直观的求解$(x, y)$的方法：
$$
(\begin{bmatrix}2&-1\\0&1\end{bmatrix})^{-1}\begin{bmatrix}4\\2\end{bmatrix}=\begin{bmatrix}x\\y\end{bmatrix}
$$

### 基变换

> 注：原始基是一个参照的基底，例如在二维中，原始基就是$\begin{bmatrix}1&0\\0&1\end{bmatrix}$

其实上面的操作，就可以理解为求解向量在另一个基（即线性变换所代表的基）的向量表示。

更广泛地，我们假设另一个基为矩阵$A$，那么当给出在这个基之上的向量$\vec{v}$时，其在**不经过任何变换**的情况下，对应到原始的基的向量就是$A\vec{v}$。

而假设$\vec{w}$是原始基的向量，那么其在基$A$上的表示则为$A^{-1}\vec{w}$

#### 线性变换的基变换

考虑如下问题，一个向量$\vec{w}$在**逆时针旋转90度**之后是什么？

这个其实很简单，考虑逆时针旋转90度所对应的线性变换是$M=\begin{bmatrix}0&-1\\1&0\end{bmatrix}$，则其在逆时针旋转90度后的向量值为$M\vec{w}$

接着考虑如下问题，我们不是在原始的基上，而是在基$A=\begin{bmatrix}2&-1\\0&1\end{bmatrix}$上，一个向量$\vec{v}$经过**逆时针旋转90度**后，是什么？

这里需要注意两个事：

- 在另一个基上，逆时针旋转90度是不可以直接用线性变换$M$来算的，因为线性变换$M$是对于原始基而言的。
- 这里要求解的向量依旧是在基$A$上的，而不是在原始基上的。

显然地，我们需要对向量$\vec{v}$做三件事情：

- 转换为原始基的表示：$A\vec{v}$
- 做逆时针90度旋转：$MA\vec{v}$
- 转换回基$A$：$A^{-1}MA\vec{v}$

那么，抛开向量，如果我们想知道某一个线性变换$M$在另一个基$A$上是怎么做的，其对应的操作就是$A^{-1}MA$

这就是线性变换的基变换。

### 线性变换的特征（Eigen）

> 这块说实话听的云里雾里的，有点知其然不知其所以然的感觉
>
> 这里先笔记着，估计还得结合后面的学习来回过头来理解

#### 特征值，特征向量

对于一个线性变换而言，可能会存在一到多个向量，这些向量在线性变换的前后**不会改变其方向，只会改变其大小**。

这些向量就是这个线性变换的**特征向量**，而缩放的倍数就是每个特征向量对应的**特征值**。

##### 如何计算

假设线性变换为$A$，特征值为$\lambda$，特征向量为$\vec{v}$，则根据定义，有：
$$
A\vec{v}=\lambda\vec{v}
$$
简化该方程可得：
$$
\begin{align*}
A\vec{v}=\lambda\vec{v} \\
A\vec{v}=\lambda I\vec{v} \\
A\vec{v}-\lambda I\vec{v}=\vec{0} \\
(A-\lambda I)\vec{v}=\vec{0} \\
\end{align*}
$$
由上可得，当且仅当$\det(A-\lambda I)=0$时，上式成立。

解这个方程得到多个$\lambda$，对每个$\lambda$求其对应的$\vec{v}$解集即可。

以$A=\begin{bmatrix}3&1\\0&2\end{bmatrix}$为例，先求解特征值：
$$
\det(A-\lambda I)=\det(\begin{bmatrix}3-\lambda&1\\0&2-\lambda\end{bmatrix})=(3-\lambda)(2-\lambda)=0
$$
解得$\lambda=2$或$\lambda=3$。

设$\vec{v}=\begin{bmatrix}x\\y\end{bmatrix}$，当$\lambda=2$时，有
$$
\begin{bmatrix}1&1\\0&0\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}0\\0\end{bmatrix}
$$
解得$y=-x$，即落在这条直线上的向量都为$\lambda=2$时的特征向量。

当$\lambda=3$时，有
$$
\begin{bmatrix}0&1\\0&-1\end{bmatrix}\begin{bmatrix}x\\y\end{bmatrix}=\begin{bmatrix}0\\0\end{bmatrix}
$$
解得$y=0$，即落在$x$轴上的向量都为$\lambda=3$时的特征向量。

##### 不一定所有的线性变换都有特征向量

举一个很简单的例子，二维空间下的旋转变换。它不存在特征向量，因为变换后每个向量都改变了方向。

同理，不一定所有的线性变换的特征向量都会落在一个低维空间里。以$\begin{bmatrix}1&0\\0&1\end{bmatrix}$为例，它的特征值为1，对应的向量为二维空间里的任意向量。

##### 有何意义

特征值和特征向量可以很好地描述这个线性变换做了什么。

其一，假设一个线性变换表示一个三维空间的旋转。如果要用矩阵表示则会很麻烦（涉及到复杂的三角函数）。

而这个矩阵对应的特征其实很简单：特征值为1，特征向量为旋转的轴。

其二，就是下面要讲到的**特征基**

#### 特征基

如果一个线性变换的特征向量刚好可以组成一个跟原线性变换相同维度的空间，则这组向量称为该线性变换的特征基。

举个例子，还是以$A=\begin{bmatrix}3&1\\0&2\end{bmatrix}$为例，上文已经求得其两个特征向量的直线为$y=-x$和$y=0$

各任取一个向量，则有$(-1, 1)$和$(1, 0)$，这两个向量构成的矩阵$B=\begin{bmatrix}1&-1\\0&1\end{bmatrix}$为$A$的特征基。

##### 有什么用

将线性变换$A$转化为其特征基$B$下的表示，根据上文可以知道其值为$B^{-1}AB$，这个矩阵**必定为对角矩阵**。

对角矩阵有很多很好用的性质，例如说其求幂会很方便（$O(n\log(k))$即可，n为矩阵维度，k为幂）。

但如果我们直接对矩阵$A$求幂，会很麻烦，最快的算法也要$O(n^3\log(k))$。

一个方便的方法是，先将矩阵$A$转换为其对应的特征基下的表示，再求幂，最后转换回来。也就是：
$$
A^k=B((B^{-1}AB)^k)B^{-1}
$$






